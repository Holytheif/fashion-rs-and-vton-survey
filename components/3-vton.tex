\section{Virtual try-on} \label{section:vton}
	Virtual try-On systems represent a cutting-edge fusion of technology and fashion retail, revolutionizing the way consumers interact with clothing online. These systems utilize artificial intelligence, computer vision, and augmented reality to simulate the experience of trying on clothing virtually. Users can see how garments fit, drape, and look on their own bodies without physically trying them on. From 2D image-based try-ons to advanced 3D models, these systems offer a range of immersive experiences.
	
	The goal of virtual try-on is not only to enhance user confidence and satisfaction, but also to reduce return rates, making it a pivotal tool in modern e-commerce. It showcases the potential of technology to bridge the gap between digital and physical retail, offering consumers an engaging and informative way to make fashion choices online.

	\subsection{Image-based (2D) virtual try-on}
		Image-based try-on systems take in images as input data and generate images as output data. The systems infer data like pose, warp, and occlusion of the target and then use that information to guide the generation of the post-try-on image.

		\lithead[MGD]{DBLP:journals/corr/abs-2304-02051}{
			Incorporates multimodal inputs such as text, body pose, and sketches and outperforms other competitors (5.57 FID) in terms of realism and coherence with multimodal inputs. Also introduces new semi-automatically annotated datasets.
		}

		\lithead[GP-VTON]{DBLP:conf/cvpr/XieHDZDZ0L23}{
			Preserves semantic information, avoids texture distortion, and handles challenging inputs by employing local flows to warp garment parts individually and dynamically truncating the gradient in the overlap area, effectively avoiding texture squeezing problems. Easily extendeds to a multi-category scenarios. FID 11.98 and SSIM 0.94. However, computational requirements of the proposed techniques, Local-Flow Global-Parsing and Dynamic Gradient Truncation, are not discussed, and has a lack of evaluation on a wider range of datasets.
		}

		\lithead[SAL-VTON]{DBLP:conf/cvpr/YanGZX23}{
			Introduces semantically associated landmarks for virtual try-on which helps in addressing misalignment issues and improving the try-on results (FID 9.52 and SSIM 0.907). Also provides the ability to edit virtual try-on results using landmarks.
		}

		\lithead[TryOnDiffusion]{DBLP:conf/cvpr/ZhuYZRCS0K23}{
			Generates apparel try-on results with significant body shape and pose modification (FID 13.447). But focuses on upper body clothing and does not experiment with full body try-on. Further, performance with more complex backgrounds is unknown.
		}

		\lithead[3D-GCL]{DBLP:conf/nips/HuangLXKCL22}{
			Incorporates 3D parametric human models as priors to better handle variations of pose and viewpoint. Utilizes 3D-aware global correspondences that encode global semantic correlations. FID 10.58.
		}

		\lithead[C-VTON]{DBLP:conf/wacv/FeleLPS22}{
			Generates convincing results even with subjects in difficult poses. Allows for the synthesis of high-quality try-on results. FID 19.54. But has issues with the masking procedure when generating image context and loose clothing. Further, lacks the ability to differentiate between the front and backside of the target garment.
		}

		\lithead[DressCode]{DBLP:conf/cvpr/MorelliFCLCC22}{
			Makes predictions at the pixel-level, resulting in high visual quality and rich in detail try-on images. FID 11.4. But is limitated in terms of representing all possible clothing categories and styles. Also, does not explicitly address issues such as occlusion, lighting variations, or realistic fabric rendering.
		}

		\lithead[HR-VTON]{DBLP:conf/eccv/LeeGPCC22}{
			Ensures information exchange and eliminates misalignment and pixel-squeezing artifacts by filtering out incorrect segmentation map predictions. FID 10.91.
		}

		\lithead[SDAFAN]{DBLP:conf/eccv/BaiZLZY22}{
			Enables clothing warping and body synthesizing simultaneously by extracting and merging feature and pixel-level information from different semantic areas. Addresses challenges without relying on intermediate parser-based labels, reducing noise and inaccuracies in the try-on process. FID 10.97. But handling of complex clothing patterns or textures is a limitation.
		}

		\lithead[RT-VTON]{DBLP:conf/cvpr/YangY022}{
			Can accurately synthesize photo-realistic results for both standard and non-standard clothes. Is able to handle hard samples such as off-shoulder clothes. Semi-rigid deformation technique used in the method balances the trade-off between rigidity and flexibility of clothes warping. FID 11.66.
		}

		\lithead{DBLP:conf/cvpr/HeSX22}{
			Proposes a perceptual loss and a warping model to train the try-on model, which helps improve the quality of the generated appearance flow and the final try-on results. Usage of a pre-trained VGG network and a parser-based model in the training process enhances the accuracy and effectiveness (FID 8.89).
		}

		\lithead{DBLP:conf/cvpr/FengMSGLLOZZ22}{
			Proposes a cheap and scalable weakly-supervised method and shows that projecting the rough alignment of clothing and body onto the StyleGAN space can yield photo-realistic wearing results. The Deep Generative Projection algorithm has a time cost for semantic and pattern searches and the method still faces difficulty against state-of-the-art methods in handling extremely complicated poses. Has an undesirably high FID score of 48.4.
		}

		\lithead[wFlow]{DBLP:conf/cvpr/DongZXZDZLLY22}{
			Is capable of transferring arbitrary garments onto challengingly-posed query person images in real-world backgrounds. Efficiently integrates the advantages of 2D pixel-flow and 3D vertex-flow. The self-supervised training scheme used in the paper leverages easily obtainable dance videos to train the model. FID 8.89. However, since it focuses on garment transfer in the context of dance videos, it is unclear how well it performs on a large scale or with diverse datasets.
		}

		\lithead[DBCT]{DBLP:conf/cvpr/FenocchiMCBCC22}{
			Improves the generation of virtual try-on results by dealing with long-range dependencies and achieving more realistic and accurate results and demonstrates its effectiveness in comparison to both standard pure convolutional approaches and previous Transformer-based proposals. FID 13.46.
		}

		\lithead[DiOr]{DBLP:conf/iccv/CuiML21}{
			Supports various fashion-related tasks such as 2D pose transfer, virtual try-on, and outfit editing. Explicitly encodes the shape and texture of each garment, allowing for separate editing of these elements. Joint training on pose transfer and inpainting helps with detail preservation and coherence of generated garments. FID 13.1. However, complex or rarely seen poses may not always be rendered correctly, and ghosting artifacts and improper filling of holes in garments can also be present.
		}

		\lithead[ZFlow]{DBLP:conf/iccv/ChopraJHK21}{
			Proposes an end-to-end framework for image-based virtual try-on addressing concerns regarding geometric and textural integrity. Incorporates gated aggregation of hierarchical flow estimates, termed Gated Appearance Flow, and dense structural priors to improve depth perception, handling of occlusion, and reduction of artifacts in try-on outputs. FID 15.17.
		}

		\lithead[FashionMirror]{DBLP:conf/iccv/ChenLHSC21}{
			Proposes a co-attention feature-remapping framework for virtual try-on to generate realistic results with spatio-temporal smoothness. Allows for refinement through convolution and generating different views. FID 5.226. However, does not address high-resolution virtual try-on, and does not provide a comprehensive analysis of the computational efficiency or scalability of the proposed framework.
		}

		\lithead[PF-AFN]{DBLP:conf/cvpr/GeSZG0021}{
			Produces highly photo-realistic try-on images without relying on human parsing by the use of appearance flows between the person image and the garment image which enables accurate dense correspondences and high-quality results. Introduces an adjustable distillation loss function to ensure accurate representations and predictions. Evaluations show the large superiority of the proposed method in terms of image quality compared to existing approaches. FID 6.429. However, heavily relies on the use of a parser-based model as the "teacher" network, which may limit the image quality of the "student" network.
		}

		\lithead[VITON-HD]{DBLP:conf/cvpr/ChoiPLC21}{
			Successfully synthesizes high-resolution virtual try-on images. Introduces a misalignment-aware normalization technique to address spatial deformation and generate properly aligned images. Utilizes conditional normalization layers to preserve semantic information and apply spatially varying affine transformations. FID 11.74.
		}

		\lithead[DCTON]{DBLP:conf/cvpr/GeSGY0021}{
			Can produce highly-realistic try-on images by disentangling important components of virtual try-on. Utilizes perceptual loss to ensure similar CNN feature representations between the warped clothes. Disentangles clothing, skin, and background components from input images. FID 14.82. However, does not differentiate clothing and non-clothing regions, which can hinder the quality of results.
		}

		\lithead[OVNet]{DBLP:conf/cvpr/LiCZL21}{
			Captures important details like buttons, shading, textures, and realistic hemlines, resulting in high-quality virtual try-on images. Introduces a technique for matching outfits with the most suitable model, leading to significant improvements in try-on results. Also consists of a semantic layout generator and an image generation pipeline using multiple coordinated warps, which yields consistent improvements in detail (FID 7.02). But does not handle variations in body shape, which limits its ability to dress garments directly on different body types. It also does not address the challenge of obtaining 3D measurements of garments and users.
		}

	\subsection{Pose-guided human synthesis}
		These systems are also image-based, but they focus on transforming a human image from reference to target pose while preserving style but changing clothing.

	\subsection{Multi-pose guided virtual try-on}
		These systems are a step up from pose-guided systems; given a input image of a person, the target clothing, and a target pose, these attempt to generate the person in the target clothing in the target pose.

	\subsection{Video virtual try-on}
		Video virtual try-on systems fit target clothes onto a person in a video with spatio-temporal consistency. This is challenging because usual image-based try-on methods cause frame-to-frame inconsistencies when applied to video data.

	\subsection{3D virtual try-on}
		3D virtual try-on systems reconstruct 3D meshes of the person and clothing from the target images and then fit the clothing onto the person in attempts to generate a physically accurate 3D render.

	\subsection{Augmented reality try-on}
		Augmented reality virtual try-on is the eventual goal of all try-on systems, integrating computer-generated imagery with real-world views, enabling users to virtually try on clothing and accessories in real-time.
		
		\lithead[]{di2020comparative}{
			Propose the use of four neural models: Fully Connected Neural Network, CNN, MobileNetV1, and MobileNetV2, to classify clothing images. Using MobileNetV2 improves the accuracy to 92.91\% but increases training time significantly.
		}

		\lithead[]{hashmi2020augmented}{
			Introduces a computationally inexpensive technique using web cam input and Haar cascade classifier that helps avoid the use of costly kinect sensors. But the sample size used limits generalizability to broader populations. Also, Haar cascade classifier may have limitations in accurately detecting specific body parts, especially under varying lighting conditions and poses.
		}

		\lithead[]{DBLP:conf/ieeehpcs/JongM19}{
			Suggests the use of simple to collect video dataset that is sufficient to successfully achieve transfer of clothing segmentations rather than using the DeepFashion dataset. But using short video datasets may limit dataset size and diversity.
		}

		\lithead[]{feng2021personalized}{
			Proposes the use of augmented reality ,Azure
			Kinect somatosensory, and OpenGL 3D rendering to provide birtual try on experience and enhance clothing customization.
		}

		\lithead[]{DBLP:journals/ijim/El-SeoudT19}{
			Provides the study of developing a Mobile Augmented Reality (MAR) application that helps store managers help in sales strategy and proposing using of AR in market and helping customer in aiding decision making without physically wearing the clothes. But it also bring the issue of long term viability and sustainabilty of such solution.
		}

		\lithead[]{DBLP:journals/sensors/BattistoniGRSVB22}{
			Explores the role of Augmented Reality as meta-user interface. It also covers case study on focus group that validates design patterns, providing insights for improvements.
		}

		\lithead[]{ali2021augmented}{
			Explores the use of smartphone camera to provide 3d image of product using augmented reality technology which provides real time A R using openCV to use camera and YOLO for detection. But using YOLO introduces constraints on bounding box predictions, impacting small object detection and unusual configurations. Also, selective search in Faster R-CNN can be time-consuming, affecting overall performance.
		}

		\lithead[]{baytar2020evaluating}{
			Provides the study of using Augmented Reality technology to help online shoppers choose their correct size and help them choose the best option based upon various attributes. S{-}O{-}R model was used to investigate how AR products were percieved by consumers. But the limited dataset reduces the generalizability of the findings. Another limitation was that the garments were 2D and did not wrap around the body.
		}

		\lithead[]{moriuchi2021engagement}{
			Provides an insight about use of chatbots and AR technology in the e{-}commerce. It included a study based upon small sample size of 68 millennials may limit generalizability.
		}

		\lithead[AVATAR]{shaw2020advanced}{
			Is capable of providing virtual apparel trial using Augmented Reality technology.AVATAR which stands for Advanced Virtual Apparel Try using Augmented Reality provides a hardware solution using IOT, OpenCV, TensorFlow and Multi-sensor body Scanner for precise body coordinates. It also facilitates face color recognition provides personalized apparel recommendations based on skin tone. But no insights about real{-}world implementation challenges were provided and no information regarding accuracy and reliability of sensors is provided.
		}




	\subsection{Commercial uses of virtual try-on}
		Companies are also using virtual try-on systems to provide enhanced experience to customers. Though many of them are limited to items like accessories and make-up, clothing try-ons are not far away.
